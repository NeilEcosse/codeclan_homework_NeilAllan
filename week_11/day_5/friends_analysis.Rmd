---
title: "R Notebook"
output: html_notebook
---

# Friends data

This uses data from the **Friends** package

Detals including the data dictionary can be found here:

https://github.com/rfordatascience/tidytuesday/issues/254


```{r, warning = F, message = F}
# install.packages("friends")
library(tidytext)
library(tidyverse)
library(here)
library(textdata)
library(ggwordcloud)
```



## Load, join and clean data

This creates the object `friends_data`

```{r, warning = F, message = F}
# Import and join data
friends_data <- friends::friends %>% 
  left_join(friends::friends_emotions, by = c("season" = "season",
                                              "episode" = "episode",
                                              "scene" = "scene",
                                              "utterance" = "utterance")
  ) %>% 
#  left_join(friends::friends_entities, by = c("season" = "season",
#                                              "episode" = "episode",
#                                              "scene" = "scene",
#                                              "utterance" = "utterance")
#  ) %>% 
    left_join(friends::friends_info, by = c("season" = "season",
                                            "episode" = "episode")
  ) %>% 
  # Get text version of episode with leading zero for single-digit episodes
  mutate(episode_text = ifelse(nchar(episode) > 1,
                               episode,
                               str_c("0", episode, sep = "")
                        )
  ) %>% 
  # Add episode text version to season to get numeric value in format "season.episode"
  mutate(season_episode =  as.numeric(str_c(season, episode_text, sep = "."))          
  ) %>% 
  # add episode number and title
  mutate(episode_number_name = str_c(episode_text, title, sep = " - ")) %>% 
  select(-episode_text)

# output this to a csv
#write_csv(friends_data, here("clean_data/friends_data"))


```

## Unnest the text data

This creates the object `friends_words`

Note that stop words have been removed.

Scene directions have also been removed.




```{r, warning = F, message = F}
# unnest text of utterance into words, remove stop words, add sentiment
friends_words <- friends_data %>%
  filter(speaker != "Scene Directions") %>% 
  unnest_tokens(word, text) %>% 
  anti_join(stop_words) %>% 
  select(-emotion) %>% 
  left_join(get_sentiments("bing")) %>% 
  left_join(get_sentiments("afinn")) %>% 
  rename("sentiment_value" = "value") %>% 
  mutate(utterance_id = as.numeric(str_c(season, episode, scene, utterance, sep = "")))
```


## Most common words

These are the fifty most commonly used words over the ten seasons of *Friends* (not including stop words)

The short words like "uh", "yeah" and gotta should probably be removed, but they do give quite a good indication of dialogue.

```{r, warning = F, message = F}
friends_words %>% 
  group_by(word) %>% 
  summarise(count = n()) %>% 
  arrange(desc(count)) %>% 
  head(50) %>% 
  ggplot()+
  aes(x = reorder(word, -count), y = count)+
  theme(axis.text.x = element_text(angle=45,hjust=1)) +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black")) +
  geom_col(fill = "steel blue") +
  labs(title = "Most common words spoken  in Friends",
       subtitle = "Total for all seasons  \n",
       x = "Word",
       y = "Count")

```
## Most common words - TF-IDF

I'll nbeed to look at this again - don't think my code is working correctly
```{r, warning = F, message = F}
friends_tf_idf <- friends_words %>%
  count(word, utterance_id) %>%
  bind_tf_idf(term = word, document = utterance_id, n = n) %>% 
  arrange(desc(tf_idf))
head(friends_tf_idf)
```

## Most common sentiment words

These are the fifty most common sentiment words which were mapped to an `afinn`sentiment value.

The colour scale shows most positive words in bright green, most negative in bright red. 

```{r, warning = F, message = F}
friends_sentiment_words <- friends_words %>% 
  filter(!is.na(sentiment_value)) %>% 
  group_by(word, sentiment_value) %>% 
  summarise(count = n()) %>% 
  arrange(desc(count)) %>% 
  head(50)
  

  friends_sentiment_words %>% 
  ggplot()+
    aes(label= word, size = count, colour = sentiment_value) +
      geom_text_wordcloud_area() +
  scale_size_area(max_size = 24) +
  theme_minimal() +
  scale_color_gradient(low = "#d7191c", high = "#1a9641")
```




## Mean sentiment value by episode and character

```{r, warning = F, message = F}
friends_words %>%
  filter(speaker %in% c("Ross Geller", "Monica Geller", "Joey Tribbiani", "Chandler Bing", "Rachel Green", "Phoebe Buffay")) %>% 
  #filter(speaker == "Ross Geller") %>% 
  filter(!is.na(sentiment_value)) %>% 
  #filter(season == 5) %>% 
  group_by(speaker, season_episode) %>% 
  summarise(sentiment_value = mean(sentiment_value)) %>% 
  ggplot()+
  aes(x = season_episode, y = sentiment_value, fill = sentiment_value) +
  geom_col()  +
  coord_flip() +
  theme(legend.position="") +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black")) +
  scale_fill_gradient2(midpoint = 0, low = "#d7191c", high = "#1a9641", mid = "#ffffbf") +
  scale_x_reverse(limits = c(10.25, 1), breaks = 1:10) +
  facet_grid(~speaker) +
  labs(
    title = "Mean sentiment value by episode and character \n",
    x = "Season & episode \n",
    y = "Sentiment value"
  )


```



## Episodes with lowest mean sentiment value - Ross
```{r}
 
friends_words %>%
  filter(speaker == "Ross Geller") %>% 
  filter(!is.na(sentiment_value)) %>% 
  group_by(season_episode, title) %>% 
  summarise(sentiment_value = mean(sentiment_value)) %>% 
  arrange(sentiment_value) %>% 
  head(5)
  
```


## Episodes with lowest mean sentiment value - Phoebe
```{r}
 
friends_words %>%
  filter(speaker == "Phoebe Buffay") %>% 
  filter(!is.na(sentiment_value)) %>% 
  group_by(season_episode, title) %>% 
  summarise(sentiment_value = mean(sentiment_value)) %>% 
  arrange(sentiment_value) %>% 
  head(5)
  
```

## Episodes with lowest mean sentiment value - Joey
```{r}
 
friends_words %>%
  filter(speaker == "Joey Tribbiani") %>% 
  filter(!is.na(sentiment_value)) %>% 
  group_by(season_episode, title) %>% 
  summarise(sentiment_value = mean(sentiment_value)) %>% 
  arrange(sentiment_value) %>% 
  head(5)
  
```



```{r}
friends_data %>% 
  group_by(season_episode) %>% 
  summarise(us_views_millions = first(us_views_millions)) %>% 
  ggplot() +
  aes(x = season_episode, y = us_views_millions) +
  geom_col()
```

```{r}
friends_data %>% any(nchar(episode) >1)
  
```

